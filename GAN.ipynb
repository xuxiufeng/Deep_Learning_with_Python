{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNuqDsi7foubbf955Usjwsm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xuxiufeng/Deep_Learning_with_Python/blob/main/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gan generator network"
      ],
      "metadata": {
        "id": "EkhZHqcPTUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "IoQWCiRkTTHo"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 32\n",
        "height = 32\n",
        "width = 32\n",
        "channels = 3\n",
        "generator_input = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Reshape((16, 16, 128))(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
        "generator = keras.models.Model(generator_input, x)\n",
        "generator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lktVYaaBTqDj",
        "outputId": "8a65ec2e-ddf6-4a43-d756-f4f29d5cf13b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 32)]              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 32768)             1081344   \n",
            "                                                                 \n",
            " leaky_re_lu_21 (LeakyReLU)  (None, 32768)             0         \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 16, 16, 256)       819456    \n",
            "                                                                 \n",
            " leaky_re_lu_22 (LeakyReLU)  (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 256)      1048832   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_23 (LeakyReLU)  (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 32, 32, 256)       1638656   \n",
            "                                                                 \n",
            " leaky_re_lu_24 (LeakyReLU)  (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 32, 32, 256)       1638656   \n",
            "                                                                 \n",
            " leaky_re_lu_25 (LeakyReLU)  (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 32, 32, 3)         37635     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,264,579\n",
            "Trainable params: 6,264,579\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The GAN discriminator network"
      ],
      "metadata": {
        "id": "i7NZAyNbXeQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "XaSWjHrsYDpd"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator_input = layers.Input(shape=(height, width, channels))\n",
        "x = layers.Conv2D(128, 3)(discriminator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "discriminator = keras.models.Model(discriminator_input, x)\n",
        "discriminator.summary()\n",
        "discriminator_optimizer = tf.keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)\n",
        "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUn2sCl9XfuZ",
        "outputId": "7a9a6fe8-700a-4ffc-aca7-1c2b02bfaa93"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 30, 30, 128)       3584      \n",
            "                                                                 \n",
            " leaky_re_lu_26 (LeakyReLU)  (None, 30, 30, 128)       0         \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 14, 14, 128)       262272    \n",
            "                                                                 \n",
            " leaky_re_lu_27 (LeakyReLU)  (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 6, 6, 128)         262272    \n",
            "                                                                 \n",
            " leaky_re_lu_28 (LeakyReLU)  (None, 6, 6, 128)         0         \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 2, 2, 128)         262272    \n",
            "                                                                 \n",
            " leaky_re_lu_29 (LeakyReLU)  (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 790,913\n",
            "Trainable params: 790,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adversarial network"
      ],
      "metadata": {
        "id": "F7NQr_LcY8D6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.trainable = False\n",
        "gan_input = keras.Input(shape=(latent_dim,)) \n",
        "gan_output = discriminator(generator(gan_input)) \n",
        "gan = keras.models.Model(gan_input, gan_output)\n",
        "gan_optimizer = tf.keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8) \n",
        "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_e0OVetYWfQ",
        "outputId": "de76f9f8-a323-40d8-849b-9840508feab4"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the data"
      ],
      "metadata": {
        "id": "Y7x0LGaDLHr0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "P5pYhaOnDj0F"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from keras.preprocessing import image\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (_, _) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train = x_train[y_train.flatten() == 6]\n",
        "x_train = x_train.reshape((x_train.shape[0],) +(height, width, channels)).astype('float32') / 255\n",
        "iterations = 10 # 10000\n",
        "batch_size = 20\n",
        "save_dir = '/content/'\n",
        "start = 0"
      ],
      "metadata": {
        "id": "e7B92L5BLPlp"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(iterations):\n",
        "    print('Progress: {}%'.format(round((step+1)/iterations*100)))\n",
        "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "    generated_images = generator.predict(random_latent_vectors)\n",
        "    stop = start + batch_size \n",
        "    real_images = x_train[start: stop]\n",
        "    combined_images = np.concatenate([generated_images, real_images])\n",
        "    labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
        "    labels += 0.05 * np.random.random(labels.shape)\n",
        "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
        "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "    misleading_targets = np.zeros((batch_size, 1))\n",
        "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
        "    start += batch_size\n",
        "    if start > len(x_train) - batch_size:\n",
        "       start = 0\n",
        "    if step % 100 == 0:\n",
        "       gan.save_weights('gan.h5')\n",
        "       print('discriminator loss:', d_loss)\n",
        "       print('adversarial loss:', a_loss)\n",
        "       img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
        "       img.save(os.path.join(save_dir,'generated_frog' + str(step) + '.png'))\n",
        "       img = image.array_to_img(real_images[0] * 255., scale=False)\n",
        "       img.save(os.path.join(save_dir,'real_frog' + str(step) + '.png'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-tNBa2-Se8u",
        "outputId": "6cf36c06-f16a-4459-8bf1-3db7d592346b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 10%\n",
            "discriminator loss: 0.7019752264022827\n",
            "adversarial loss: 0.653041422367096\n",
            "Progress: 20%\n",
            "Progress: 30%\n",
            "Progress: 40%\n",
            "Progress: 50%\n",
            "Progress: 60%\n",
            "Progress: 70%\n",
            "Progress: 80%\n",
            "Progress: 90%\n",
            "Progress: 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference\n",
        "* Learning Multiple Layers of Features from Tiny Images, Alex Krizhevsky, 2009\n",
        "* Chollet, F., (2017), Deep Learning, ISBN: 9781638352044, 1638352046"
      ],
      "metadata": {
        "id": "FaYuex5vLSe2"
      }
    }
  ]
}